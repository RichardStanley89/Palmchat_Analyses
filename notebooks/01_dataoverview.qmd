---
title: "dataoverview"
format: html
editor: visual
---

# Introduction

## Palmchat Banding Data:

The Palmchat Banding Data spreadsheet contains data on the individual birds that were captured, banded, and released at my field site in Punta Cana in the Dominican Republic. This spreadsheet is for keeping track of the identity of individual birds (which have unique numbers and band color combinations), as well as the characteristics of each bird (eg. body size, male or female, age where known, and other morphological characteristics). Because many different field assistants contributed to collecting this data, there are some differences in how the data were collected over different time periods (eg. Sometimes it was possible to age birds in the field based on molt patterns, but not every observer could do this, and sometimes their age scoring systems were slightly different)

```{r setup, message=FALSE}
# Load the libraries
library("tidyverse")
library("dplyr")
library("asnipe")
library("igraph")
library("statnet")

set.seed(857)

```

We are loading the three datasets here, and taking a quick look. The `Dyads` data is the sightings

```{r load_data}
rawdata <- read.csv("../rawdata/PalmchatBandingDataAll.csv")
head(rawdata)
edges <- read.csv("../rawdata/PalmchatDyads.csv")
head(edges)
```

## Cleaning

### Uncertainty removal

First we want to filter out the dyads with unbanded birds, which is around \~260 observations

```{r}
unbanded <- edges %>% 
  filter(str_detect(Individual1, "U") | str_detect(Individual2, "U") |
         str_detect(Individual1, "juv") | str_detect(Individual2, "juv"))

slice_head(unbanded, n=10)  

nrow(unbanded)
```

J: are these observations with unbanded individuals evenly spread over the study period? Or are there any specific days that are overrepresented?

```{r}
unbanded %>% 
  mutate(Date = lubridate::ymd(Date)) %>% 
  ggplot(aes(x = Date)) +
  geom_bar()
```

We have \~800 observations now, and have to remove the ones with uncertainty

```{r}
edges %>% 
  anti_join(unbanded)
```

Interesting that some of the uncertain id ones also have an unbanded, reducing data loss.

```{r}
uncertain_id <- edges %>% 
  filter(str_detect(Individual1, "\\?") | str_detect(Individual2, "\\?"))
head(uncertain_id)

```

Now we can get the clean_edges by removing the unbanded, uncertain id and juveniles unbanded

```{r clean_edges, message=FALSE}
clean_edges <- edges %>% 
  anti_join(unbanded) %>% 
  anti_join(uncertain_id) %>% 
  mutate(Individual1 = str_trim(Individual1),
         Individual2 = str_trim(Individual2))
```

## Fix Bands

```{r}
# Step 1: identify the individual ids
band_ids <- unique(c(clean_edges$Individual1, clean_edges$Individual2)) %>% 
  str_trim()

# Step 2: separate the ones that have a missing band
ids_with_dash <- str_subset(band_ids, "-")
ids_with_dash

# W-WM this one is a true id because they ran out of bands
# remove from list
ids_with_dash <- ids_with_dash[ids_with_dash != "W-WM"]
ids_with_dash

# Step 3: identify potential matches:
create_pattern <- function(id) {
  str_replace_all(id, "-", ".")
}

patterns <- sapply(ids_with_dash, create_pattern)

# Step 3: Use str_detect to find all matching IDs
matches <- sapply(patterns, function(pattern) {
  matched_ids <- str_subset(band_ids, pattern)
  return(matched_ids)
})

names(matches) <- ids_with_dash
print(matches)

```

Those seem harder to resolve. Maybe we can filter by location?

```{r}
# Double check that there are only two sites:
unique(clean_edges$Site)

# Separate the dataset based on the 'site' variable
clean_edges_hacienda <- clean_edges %>% filter(Site == "Hacienda")
clean_edges_corales <- clean_edges %>% filter(Site == "Corales")

# Repeat process for both:
get_ids_with_dash <- function(clean_edges_subset) {
  # Step 1: Identify the individual IDs
  band_ids <- unique(c(clean_edges_subset$Individual1, clean_edges_subset$Individual2)) %>%
    str_trim()
  
  # Step 2: Separate the ones that have a missing band
  ids_with_dash <- str_subset(band_ids, "-") %>%
    .[. != "W-WM"]  # Remove the known valid ID
  
  band_ids_no_dash <- setdiff(band_ids, ids_with_dash)
  
  # Step 3: Identify potential matches
  create_pattern <- function(id) {
    str_replace_all(id, "-", ".")
  }
  patterns <- sapply(ids_with_dash, create_pattern)
  
  # Step 4: Use str_detect to find all matching IDs
  matches <- sapply(patterns, function(pattern) {
    matched_ids <- str_subset(band_ids_no_dash, pattern)
    return(matched_ids)
  })
  names(matches) <- ids_with_dash
  
  return(
    list(ids_with_dash = ids_with_dash,
         matches = matches)
  )
  
}

# Process each subset
cat("Hacienda \n")
get_ids_with_dash(clean_edges_hacienda)

cat("Corales \n")
get_ids_with_dash(clean_edges_corales)
```

I don't think we can resolve these uncertain banding patterns. Let's check how much data we lose if we take them out:

```{r}
ids_with_dash

# it's just 1 observation here
clean_edges_hacienda %>% 
  filter(Individual1 %in% ids_with_dash | Individual2 %in% ids_with_dash)

# It's 18 observations here
clean_edges_corales %>% 
  filter(Individual1 %in% ids_with_dash | Individual2 %in% ids_with_dash)

# We can fix one of these:
# "Y-NM" => "YBNM"

clean_edges %>% 
  mutate(Individual1 = ifelse(Individual1 == "Y-NM", "YBNM", Individual1),
         Individual2 = ifelse(Individual1 == "Y-NM", "YBNM", Individual2)) -> clean_edges

# and also wondering if the "Y-BM" could be a misread of "YBNM"
# It's only 2 observations
clean_edges %>% 
  filter(Individual1 == "Y-BM" | Individual2 == "Y-BM")
```

For the sake of certainty, for now, let's just remove the unresolved observations. Unfortunately, for the corales data, some of the ones we are removing also show as group interactions, so I don't know if there is a way we can keep that data.

```{r}
# We get 638 observations here
clean_edges_no_dash <- clean_edges %>% 
  filter(!(Individual1 %in% ids_with_dash | Individual2 %in% ids_with_dash)) %>%
  filter(Individual1!="YNGM") %>%
  filter(Individual2!="WWGM")

# clean_edges %>% 
#   filter(Individual1 %in% ids_with_dash | Individual2 %in% ids_with_dash)
  

clean_edges_no_dash %>% 
  count(Site)
```

I also found that some of the observations have patterns with only 3 letters, which doesn't work here. Need to check these with Rick but for now, removing.

```{r}

unique(clean_edges$Individual1)


band_ids_w_3 <- band_ids[str_length(band_ids) == 3]
band_ids_w_3

# Unsure if these could match anything else
# But it is only 3 observations, so I think we might need to remove them as well
clean_edges_no_dash %>% 
  filter(Individual1 %in% band_ids_w_3 | Individual2 %in% band_ids_w_3)

filtered_indices <- which(clean_edges_no_dash$Individual1 %in% band_ids_w_3 |
                            clean_edges_no_dash$Individual2 %in% band_ids_w_3)

filtered_indices

clean_edges_no_dash[filtered_indices,]

clean_edges_no_dash$Individual2[85] <- "RBWM"
clean_edges_no_dash$Individual1[90] <- "W-WM"
clean_edges_no_dash$Individual2[312] <- "YGOM"

# Check overwritten:
clean_edges_no_dash[filtered_indices,]
```

As I was working with the attributes below, I also found a couple with only 2 letters, so checking those:

```{r}

band_ids_w_2 <- band_ids[str_length(band_ids) == 2]
band_ids_w_2

# It's only one, check how many in the observations
clean_edges_no_dash %>% 
  filter(Individual1 %in% band_ids_w_2 | Individual2 %in% band_ids_w_2)

# single row, so just remove it
which(clean_edges_no_dash$Individual1 %in% band_ids_w_2 |
                            clean_edges_no_dash$Individual2 %in% band_ids_w_2)

```

# Add dyad-id

## Fix edge list for consistency in the order

We want to make sure that order is consistent (eg. BSY--YGG vs. YGG--BSY, which represent the same interaction, should always be in the same order to avoid confusion. Because we have the individuals with same band pattern, we also want to do this by site, and removing any observations that have missing bands.

```{r}

clean_edges_with_dyad_id <- clean_edges_no_dash %>% 
  # filter(!(Individual1 %in% band_ids_w_3 | Individual2 %in% band_ids_w_3)) %>% #fixed
  filter(!(Individual1 %in% band_ids_w_2 | Individual2 %in% band_ids_w_2)) %>% 
  group_by(Site) %>% 
  # get them sorted by alphabetical
  mutate(
    sorted_Individual1 = pmin(Individual1, Individual2),
    sorted_Individual2 = pmax(Individual1, Individual2), .after = Individual2
  ) %>%
  # combine for id, use underscore _ so it doesn't confuse with id missing band
  mutate(dyad_id = paste(sorted_Individual1, sorted_Individual2, sep = "_"), .after = Individual2) %>%
  select(-sorted_Individual1, -sorted_Individual2) %>% 
  ungroup()

clean_edges_with_dyad_id %>% slice_sample(n=15)
```

I want to see how many unique values we have, and how many times we saw them, and where. We have \~600 observations, and 215 distinct dyads

```{r}
weighted_edges <- clean_edges_with_dyad_id %>% 
  group_by(
    Site
    #, Group.Interaction.
    ) %>% 
  dplyr::count(dyad_id, name = "weight") %>% 
  arrange(desc(weight))

head(weighted_edges)
```

## Basic analysis

Build a dataframe that can be used by statnet:

```{r}
edges_for_network <- weighted_edges %>% 
  separate_wider_delim(., cols = dyad_id, "_", names = c("ID1", "ID2")) 
head(edges_for_network)
```

We have the data separated by site, and I am not fully sure that's they way, but I suspect it might be relevant. Specially given we had two animals banded the same but in different sites. Start with the site that has most obsevations, then repeat?

```{r}
# 1. Build the network object
edges_for_network %>% 
  count(Site)

# Get data for one of the sites only:
hacienda_edges <- edges_for_network %>% 
  filter(Site == "Hacienda") %>%
  ungroup() %>%
  select(-Site) 

# Build the network - use igraph first
hacienda_network <- graph_from_data_frame(
  d = hacienda_edges[, c("ID1", "ID2", "weight")], 
  directed = FALSE
)

# Check if weight was loaded
# E(hacienda_network)$weight # It was

# Basic network properties
cat("Number of birds:", vcount(hacienda_network), "\n")
cat("Number of unique dyads:", ecount(hacienda_network), "\n")
cat("Network density:", edge_density(hacienda_network), "\n")
cat("Average degree:", mean(igraph::degree(hacienda_network)), "\n")

```

The network included 82 birds forming 166 unique associations. Birds were selective in their social partners, with each individual associating with an average of only 4 others out of the 81 possible companions. The low network density (0.05) indicates that palmchats do not mix freely across the entire population, but rather maintain specific social connections.

Well, now I have another question. I see this and recognize some band_ids that have only 3 letters and wondering if that is ok or they are mistakes:

```{r}


#Next: What's the range of degrees? Some birds might be very social while others are peripheral

write.csv(clean_edges_hacienda, "PalmchatEdges.csv")

# With igraph:
deg <- igraph::degree(hacienda_network)
cat("Degree range:", min(deg), "to", max(deg), "\n")
cat("Median degree:", median(deg), "\n")

sort(deg)

# Look at the distribution
hist(deg, breaks = 20,
     main = "Distribution of Social Connections",
     xlab = "Number of associates per bird",
     ylab = "Number of birds")

# Who are the most connected birds?
head(sort(deg, decreasing = TRUE), 10)
```

"Hub" birds with many connections. The degree distribution was right-skewed, with most birds maintaining only 1-3 social connections while a few individuals associated with 10 or more others. This pattern suggests that most palmchats have small, selective social circles, with a handful of highly connected individuals potentially acting as bridges between groups. This skewed distribution is consistent with modular social structure rather than random mixing—if birds associated indiscriminately across the population, we would expect a more symmetrical distribution centered around the mean degree of 4.

## Modularity analysis

```{r}
# Community detection
# ?cluster_louvain
comm_louvain <- cluster_louvain(hacienda_network, weights = E(hacienda_network)$weight)

# Key metrics
cat("Modularity:", modularity(comm_louvain), "\n")
cat("Number of groups detected:", length(comm_louvain), "\n")

# Group sizes
group_sizes <- sort(sizes(comm_louvain), decreasing = TRUE)
print(group_sizes)

# Clustering coefficient
obs_clustering <- transitivity(hacienda_network, type = "global")
random_expected <- edge_density(hacienda_network)

cat("Observed clustering coefficient:", round(obs_clustering, 3), "\n")
cat("Expected if random:", round(random_expected, 3), "\n")
cat("Ratio (obs/expected):", round(obs_clustering / random_expected, 2), "x\n")
```

The Louvain algorithm detects communities (groups) in the network by iteratively optimizing modularity, which is a measure of how well the network divides into densely connected subgroups with sparse connections between them. The algorithm identifies groups where birds associate more frequently with each other than expected by chance.

This detected 12 distinct social groups (sizes 2-14 birds) with exceptionally high modularity (0.74), indicating clearly defined community structure. The clustering coefficient was 6.4 times higher than random expectation, meaning birds sharing mutual associates were highly likely to associate themselves, so pointing towards tight-knit social groups where "friends of friends" tend to be friends. These results show that palmchats maintain organized, non-random social relationships rather than mixing freely across the population.

```{r}
# Group membership
membership(comm_louvain)


m <- membership(comm_louvain)
m

```

```{r}
# Basic visualization colored by group
# You can do fancier with ggraph
plot(comm_louvain, hacienda_network,
     vertex.size = 5,
     vertex.label = NA,
     edge.width = E(hacienda_network)$weight / 2,  # scale edge width by observations
     main = "Hacienda Site")
```

```{r}
# Generate random networks with same degree distribution
n_permutations <- 1000
null_modularity <- numeric(n_permutations)

for(i in 1:n_permutations) {
  # Randomly permute edges while keeping degree sequence
  random_net <- rewire(hacienda_network, keeping_degseq(niter = ecount(hacienda_network) * 10))
  random_comm <- cluster_louvain(random_net, weights = E(random_net)$weight)
  null_modularity[i] <- modularity(random_comm)
}

# Compare observed to null
observed_mod <- modularity(comm_louvain)
# What proportion of random networks had modularity >= observed?
p_value <- mean(null_modularity >= observed_mod)
# Calculate z-score for effect size assuming normal dist
z_score <- (observed_mod - mean(null_modularity)) / sd(null_modularity)

# Report results
cat("Observed modularity:", round(observed_mod, 4), "\n")
cat("Mean null modularity:", round(mean(null_modularity), 4), "\n")
cat("SD null modularity:", round(sd(null_modularity), 4), "\n")
cat("Z-score:", round(z_score, 2), "\n")
cat("P-value:", p_value, "\n")

# Visualize
hist(null_modularity, breaks = 30, 
     main = "Modularity: Observed vs. Random Networks",
     xlab = "Modularity",
     col = "lightgray",
     xlim = range(c(null_modularity, observed_mod)))
abline(v = observed_mod, col = "red", lwd = 3)
abline(v = mean(null_modularity), col = "blue", lwd = 2, lty = 2)
legend("topright", 
       c("Observed", "Null mean"), 
       col = c("red", "blue"), 
       lwd = c(3, 2), 
       lty = c(1, 2))
text(x = observed_mod, y = par("usr")[4] * 0.9, 
     labels = paste0("Z = ", round(z_score, 2)), 
     pos = 4, col = "red")

```

Permutation tests (1,000 iterations) confirmed that the observed social structure was highly non-random. The observed modularity (0.74) was significantly higher than expected by chance (mean null = 0.44, z = 23.76, p \< 0.001), with none of the randomized networks approaching the modularity of the actual palmchat network.

::: note
Rick, next steps are to repeat these analyses with the other site. You also mentioned doing it by season, so you could try separating the data by season and comparing the results.
:::

# Adding attributes

Trying to answer

2)  Understanding Predictors of Social Structure:

· What drives the patterns of social associations in palmchat networks? (eg., are birds more likely to be connected in the network or belong to the same social group if they have certain characteristics)?

· Do birds from the same nest belong to the same social group? (answer here will likely be yes).

· Do social groups typically have more males than females?

# Attributes

Let's take a look at the attributes associated with each bird, in the raw banding data: Clean out the recaptures first

```{r}
# There is an error in the banding process here
# These are new captures but accidentally got the same color combination as a previous new bird

rawdata %>% 
  filter(Status == "N") %>% 
  anti_join(
    rawdata %>% distinct(Colors, .keep_all = TRUE) 
  )

```

# These are the banding errors. Which we can probably keep since they are in different sites. So, recommendation, keep in mind when doing the network analysis, to do it by site. (we did)

```{r}
rawdata %>% 
  filter(Colors %in% c("GBBM", "RBBM"), Status == "N") %>% 
  select(Location, Colors)
```

Based on this, we create the attribute table to keep the repeat birds since they are from different locations.

```{r}
attributes <- rawdata %>% 
  filter(Status == "N")
```

```{r}

# let's get rid of the columns we're not interested in, just to make things tidier:

attributes_clean <- attributes %>% 
  select(
    Year, Month, Day, Colors, Location, Molecular_Sex, Body_Mass, UNFLT_Wing, 
    Age, Entrance_affiliation_based_on_videos_2024, Nest_affiliation..2024.
    ) %>% 
  janitor::clean_names()

head(attributes_clean)

```

Filter to hacienda to join with the network above:

```{r}
# Get the bird ids from the hacienda network
hacienda_ids <- V(hacienda_network)$name

hacienda_ids

attributes_clean %>% 
  filter(location == "Hacienda") # 129 banded/captured

# We have a mismatch, or perhaps an error here
# The ids recovered from the hacienda observations seem to match birds initially captured in corales, which tells me we probably can't differentiate between those birds that were duplicated with the bands


hacienda_attributes <- attributes_clean %>% 
  filter(!(colors == "RBBM" & location == "Corales")) %>%
  filter(!(colors == "GBBM" & location == "Corales_Entrance")) %>% 
  filter(colors %in% hacienda_ids) 



write.csv(hacienda_attributes, "Attributes.csv")


attribute_ids <- hacienda_attributes$colors
missing_birds <- setdiff(hacienda_ids, attribute_ids)
# Why do we have missing birds from the attribute?

# fixed this in raw data

# GSSM
# SGRM

# let's remove two irrelevant birds from the attribute dataset, the birds with duplicate band colors (only the Hacienda ones show up in the social data):




hacienda_attributes$colors

hacienda_ids_sorted <- sort(hacienda_ids)
hacienda_ids_sorted

attribute_ids_sorted <- sort(hacienda_attributes$colors)
attribute_ids_sorted


```

Let's make a Corales network:

```{r}
corales_edges <- edges_for_network %>% 
  filter(Site == "Corales") %>%
  ungroup() %>%
  select(-Site) 


# Build the network - use igraph first
corales_network <- graph_from_data_frame(
  d = corales_edges[, c("ID1", "ID2", "weight")], 
  directed = FALSE
)
```

Let's check the data for the Corales site, to see if the network associations there match up with the attribute data the way that they should:

```{r}
# # Get the bird ids from the hacienda network
corales_ids <- V(corales_network)$name

corales_ids

corales_attributes <- attributes_clean %>% 
  filter(location == "Corales")

# let's filter out the problematic IDs from the dataset, so we don't have to worry about them:


corales_attributes_ids <- corales_attributes %>% 
   filter(colors != "WWGM") %>%
  filter(colors %in% corales_ids) 


corales_ids_sorted <- sort(corales_ids)
corales_ids_sorted

corales_attribute_ids_sorted <- sort(corales_attributes_ids$colors)
corales_attribute_ids_sorted


```

## Basic analysis

We have the data separated by site, and I am not fully sure that's they way, but I suspect it might be relevant. Specially given we had two animals banded the same but in different sites. Start with the site that has most obsevations, then repeat?

```{r}

# Build the network - use igraph first
corales_network <- graph_from_data_frame(
  d = corales_edges[, c("ID1", "ID2", "weight")], 
  directed = FALSE
)

# Check if weight was loaded
# E(hacienda_network)$weight # It was

# Basic network properties
cat("Number of birds:", vcount(corales_network), "\n")
cat("Number of unique dyads:", ecount(corales_network), "\n")
cat("Network density:", edge_density(corales_network), "\n")
cat("Average degree:", mean(igraph::degree(corales_network)), "\n")

```

The network included 34 birds forming 47 unique associations. The low network density (0.08) indicates that palmchats do not mix freely across the entire population, but rather maintain specific social connections.

```{r}

#Next: What's the range of degrees? Some birds might be very social while others are peripheral

# With igraph:
deg <- igraph::degree(corales_network)
cat("Degree range:", min(deg), "to", max(deg), "\n")
cat("Median degree:", median(deg), "\n")

# Look at the distribution
hist(deg, breaks = 20,
     main = "Distribution of Social Connections",
     xlab = "Number of associates per bird",
     ylab = "Number of birds")

# Who are the most connected birds?
head(sort(deg, decreasing = TRUE), 10)
```

## Modularity analysis

```{r}
# Community detection
# ?cluster_louvain
comm_louvain <- cluster_louvain(corales_network, weights = E(corales_network)$weight)

# Key metrics
cat("Modularity:", modularity(comm_louvain), "\n")
cat("Number of groups detected:", length(comm_louvain), "\n")

# Group sizes
group_sizes <- sort(sizes(comm_louvain), decreasing = TRUE)
print(group_sizes)

# Clustering coefficient
obs_clustering <- transitivity(corales_network, type = "global")
random_expected <- edge_density(corales_network)

cat("Observed clustering coefficient:", round(obs_clustering, 3), "\n")
cat("Expected if random:", round(random_expected, 3), "\n")
cat("Ratio (obs/expected):", round(obs_clustering / random_expected, 2), "x\n")
```

The Louvain algorithm detects communities (groups) in the network by iteratively optimizing modularity, which is a measure of how well the network divides into densely connected subgroups with sparse connections between them. The algorithm identifies groups where birds associate more frequently with each other than expected by chance.

This detected 7 distinct social groups (sizes 2-7 birds) with exceptionally high modularity (0.72), indicating clearly defined community structure. The clustering coefficient was 4.16 times higher than random expectation, meaning birds sharing mutual associates were highly likely to associate themselves, so pointing towards tight-knit social groups where "friends of friends" tend to be friends. These results show that palmchats maintain organized, non-random social relationships rather than mixing freely across the population.

```{r}
# Group membership
membership(comm_louvain)

```

```{r}
# Basic visualization colored by group
# You can do fancier with ggraph
plot(comm_louvain, corales_network,
     vertex.size = 5,
     vertex.label = NA,
     edge.width = E(hacienda_network)$weight / 2,  # scale edge width by observations
     main = "Corales Site")
```

```{r}
# Generate random networks with same degree distribution
n_permutations <- 1000
null_modularity <- numeric(n_permutations)

for(i in 1:n_permutations) {
  # Randomly permute edges while keeping degree sequence
  random_net <- rewire(corales_network, keeping_degseq(niter = ecount(corales_network) * 10))
  random_comm <- cluster_louvain(random_net, weights = E(random_net)$weight)
  null_modularity[i] <- modularity(random_comm)
}

# Compare observed to null
observed_mod <- modularity(comm_louvain)
# What proportion of random networks had modularity >= observed?
p_value <- mean(null_modularity >= observed_mod)
# Calculate z-score for effect size assuming normal dist
z_score <- (observed_mod - mean(null_modularity)) / sd(null_modularity)

# Report results
cat("Observed modularity:", round(observed_mod, 4), "\n")
cat("Mean null modularity:", round(mean(null_modularity), 4), "\n")
cat("SD null modularity:", round(sd(null_modularity), 4), "\n")
cat("Z-score:", round(z_score, 2), "\n")
cat("P-value:", p_value, "\n")

# Visualize
hist(null_modularity, breaks = 30, 
     main = "Modularity: Observed vs. Random Networks",
     xlab = "Modularity",
     col = "lightgray",
     xlim = range(c(null_modularity, observed_mod)))
abline(v = observed_mod, col = "red", lwd = 3)
abline(v = mean(null_modularity), col = "blue", lwd = 2, lty = 2)
legend("topright", 
       c("Observed", "Null mean"), 
       col = c("red", "blue"), 
       lwd = c(3, 2), 
       lty = c(1, 2))
text(x = observed_mod, y = par("usr")[4] * 0.9, 
     labels = paste0("Z = ", round(z_score, 2)), 
     pos = 4, col = "red")

```

Permutation tests (1,000 iterations) confirmed that the observed social structure was highly non-random. The observed modularity (0.72) was significantly higher than expected by chance (mean null = 0.49, z = 9.68, p \< 0.001), with none of the randomized networks approaching the modularity of the actual palmchat network.

We have some mismatches and things to clean here:

```{r}
# Check what "empty" cells actually contain
unique(hacienda_attributes$molecular_sex)
unique(hacienda_attributes$nest_affiliation_2024)
unique(hacienda_attributes$entrance_affiliation_based_on_videos_2024)

# Check for empty strings, spaces, etc.
table(hacienda_attributes$molecular_sex, useNA = "always")
table(hacienda_attributes$nest_affiliation_2024, useNA = "always")
```

```{r}
# Convert empty strings and spaces to NA
hacienda_attributes_clean <- hacienda_attributes %>%
  mutate(
    molecular_sex = na_if(molecular_sex, ""),
    molecular_sex = na_if(molecular_sex, " "),
    # Clean entrance_affiliation (empty strings to NA)
    entrance_affiliation_based_on_videos_2024 = na_if(entrance_affiliation_based_on_videos_2024, ""),
    entrance_affiliation_based_on_videos_2024 = na_if(entrance_affiliation_based_on_videos_2024, " "),
    # Clean nest_affiliation_2024 (empty strings and "Unknown" to NA)
    nest_affiliation_2024 = na_if(nest_affiliation_2024, ""),
    nest_affiliation_2024 = na_if(nest_affiliation_2024, " "),
    nest_affiliation_2024 = na_if(nest_affiliation_2024, "Unknown")
  ) %>% 
  mutate(
    nest_affiliation_2024 = case_when(
      nest_affiliation_2024 == "Nest_10 AND Nest_1" ~ "Nest_10",
      TRUE ~ nest_affiliation_2024
    ))



# Check the result
table(hacienda_attributes_clean$nest_affiliation_2024, useNA = "always")
sum(is.na(hacienda_attributes_clean$molecular_sex))
sum(is.na(hacienda_attributes_clean$nest_affiliation_2024))
sum(is.na(hacienda_attributes_clean$entrance_affiliation_based_on_videos_2024))
```

We can't include the entrance affiliation, not enough data, we are missing 51/82. So need to incorporate this into your results as a descriptive result for the \~30 data points. For the other two variables we can include since we've got 60 and 80% of the birds with data on them.

```{r}
# Check for duplicate birds
dup_birds <- hacienda_attributes_clean$colors[duplicated(hacienda_attributes_clean$colors)]

cat("Birds appearing multiple times:", length(dup_birds), "\n")
  print(hacienda_attributes_clean %>% 
        filter(colors %in% dup_birds) %>% 
        select(colors, year, month, day, location, nest_affiliation_2024, molecular_sex) %>%
        arrange(colors))
```

```{r}

# create a network object in statnet

network <- network(edges,matrix.type="edgelist", directed=FALSE)

list.edge.attributes(network)
as.edgelist(network)
get.edge.attribute(network, "weight")
list.vertex.attributes(network)

# 

### Now we need to add some other node attribute data to the network: eg. the Nest
# affiliation of each bird in the network, body mass, etc. However, the order
# of the data in the attributes data set differs from the order in the network.
# Let's work on this issue so we have a properly labeled network:

# line up vertex attributes in the same order as the network vertex data in statnet:

# let's double check what the order is in the network:
get.vertex.attribute(network,"vertex.names")

# first, create a column with the same names in each dataset so you can perform a join:


df <- mutate(attributes, col1 = Colors)
df2 <- data.frame(col1 = network.vertex.names(network))


# now, perform a join to get them in the right order.
# As a result of this, the attributes will now be in the same
# order as the nodes in the network:

dfjoined <- left_join(df2, df, by ="col1")

str(dfjoined$Nest_affiliation..2024.)
length(dfjoined$Nest_affiliation..2024.)

# now, add these node attributes to the statnet network.

# First, add the attribute "NestID"

set.vertex.attribute(network, "NestID", dfjoined$Nest_affiliation..2024.)

get.vertex.attribute(network,"NestID")

# assess the length and number of NAs in the new network attribute, NestID

sum(is.na(dfjoined$Nest_affiliation..2024.))
length(dfjoined$Nest_affiliation..2024.)
network.size(network)

# add the attribute "EntranceID"

set.vertex.attribute(network,"EntranceID", dfjoined$Entrance_affiliation_based_on_videos_2024)

get.vertex.attribute(network,"EntranceID")

list.vertex.attributes(network)
list.edge.attributes(network)

vertexnames <- get.vertex.attribute(network,"vertex.names")
vertexnames


# add the attribute "Sex"

set.vertex.attribute(network,"Sex", dfjoined$Molecular_Sex)

get.vertex.attribute(network,"Sex")


```

```{r}
# let's also load the data in group format, as a list (since this is the input
# preferred by the "asnipe" package, and it preserves information about group interactions)


groupdata <- read.csv("../rawdata/PalmchatGroups.csv")

# let's filter out sightings with ID uncertainty:

groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual1, "\\?"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual2, "\\?"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual3, "\\?"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual4, "\\?"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual5, "\\?"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual6, "\\?"))

# and sightings with unbanded birds

groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual1, "U"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual2, "U"))


# now let's put this data into a list format for the asnipe package:


groups <- groupdata %>% select(Individual1, Individual2, Individual3, Individual4,
                               Individual5, Individual6, Individual7, Individual8)

groups <- apply(groups, 1, as.list)

print(groups)

# and let's use this function from the asnipe package to create a matrix:

GBI <- get_group_by_individual(groups,
                               data_format="groups")

GBI
```
