---
title: "dataoverview"
format: html
editor: visual
---

# Introduction

## Palmchat Banding Data:

The Palmchat Banding Data spreadsheet contains data on the individual birds that were captured, banded, and released at my field site in Punta Cana in the Dominican Republic. This spreadsheet is for keeping track of the identity of individual birds (which have unique numbers and band color combinations), as well as the characteristics of each bird (eg. body size, male or female, age where known, and other morphological characteristics). Because many different field assistants contributed to collecting this data, there are some differences in how the data were collected over different time periods (eg. Sometimes it was possible to age birds in the field based on molt patterns, but not every observer could do this, and sometimes their age scoring systems were slightly different)

```{r setup, message=FALSE}
# Load the libraries
library("tidyverse")
library("dplyr")
library("asnipe")
library("igraph")
library("statnet")

```

We are loading the three datasets here, and taking a quick look. The `Dyads` data is the sightings

```{r load_data}
rawdata <- read.csv("../rawdata/PalmchatBandingDataAll.csv")
head(rawdata)
edges <- read.csv("../rawdata/PalmchatDyads.csv")
head(edges)
```

## Cleaning

### Uncertainty removal

First we want to filter out the dyads with unbanded birds, which is around \~260 observations

```{r}
unbanded <- edges %>% 
  filter(str_detect(Individual1, "U") | str_detect(Individual2, "U") |
         str_detect(Individual1, "juv") | str_detect(Individual2, "juv"))

slice_head(unbanded, n=10)  

nrow(unbanded)
```

J: are these observations with unbanded individuals evenly spread over the study period? Or are there any specific days that are overrepresented?

```{r}
unbanded %>% 
  mutate(Date = lubridate::ymd(Date)) %>% 
  ggplot(aes(x = Date)) +
  geom_bar()
```

We have \~800 observations now, and have to remove the ones with uncertainty

```{r}
edges %>% 
  anti_join(unbanded)
```

Interesting that some of the uncertain id ones also have an unbanded, reducing data loss.

```{r}
uncertain_id <- edges %>% 
  filter(str_detect(Individual1, "\\?") | str_detect(Individual2, "\\?"))
head(uncertain_id)

```


Now we can get the clean_edges by removing the unbamded, uncertain id and juveniles unbanded

```{r clean_edges, message=FALSE}
clean_edges <- edges %>% 
  anti_join(unbanded) %>% 
  anti_join(uncertain_id) %>% 
  mutate(Individual1 = str_trim(Individual1),
         Individual2 = str_trim(Individual2))
```

## Fix Bands

```{r}
# Step 1: identify the individual ids
band_ids <- unique(c(clean_edges$Individual1, clean_edges$Individual2)) %>% 
  str_trim()

# Step 2: separate the ones that have a missing band
ids_with_dash <- str_subset(band_ids, "-")
ids_with_dash

# W-WM this one is a true id because they ran out of bands
# remove from list
ids_with_dash <- ids_with_dash[ids_with_dash != "W-WM"]
ids_with_dash

# Step 3: identify potential matches:
create_pattern <- function(id) {
  str_replace_all(id, "-", ".")
}

patterns <- sapply(ids_with_dash, create_pattern)

# Step 3: Use str_detect to find all matching IDs
matches <- sapply(patterns, function(pattern) {
  matched_ids <- str_subset(band_ids, pattern)
  return(matched_ids)
})

names(matches) <- ids_with_dash
print(matches)

```
Those seem harder to resolve. Maybe we can filter by location? 


```{r}
# Double check that there are only two sites:
unique(clean_edges$Site)

# Separate the dataset based on the 'site' variable
clean_edges_hacienda <- clean_edges %>% filter(Site == "Hacienda")
clean_edges_corales <- clean_edges %>% filter(Site == "Corales")

# Repeat process for both:
get_ids_with_dash <- function(clean_edges_subset) {
  # Step 1: Identify the individual IDs
  band_ids <- unique(c(clean_edges_subset$Individual1, clean_edges_subset$Individual2)) %>%
    str_trim()
  
  # Step 2: Separate the ones that have a missing band
  ids_with_dash <- str_subset(band_ids, "-") %>%
    .[. != "W-WM"]  # Remove the known valid ID
  
  band_ids_no_dash <- setdiff(band_ids, ids_with_dash)
  
  # Step 3: Identify potential matches
  create_pattern <- function(id) {
    str_replace_all(id, "-", ".")
  }
  patterns <- sapply(ids_with_dash, create_pattern)
  
  # Step 4: Use str_detect to find all matching IDs
  matches <- sapply(patterns, function(pattern) {
    matched_ids <- str_subset(band_ids_no_dash, pattern)
    return(matched_ids)
  })
  names(matches) <- ids_with_dash
  
  return(
    list(ids_with_dash = ids_with_dash,
         matches = matches)
  )
  
}

# Process each subset
cat("Hacienda \n")
get_ids_with_dash(clean_edges_hacienda)

cat("Corales \n")
get_ids_with_dash(clean_edges_corales)
```
I don't think we can resolve these uncertain banding patterns. Let's check how much data we lose if we take them out:

```{r}
ids_with_dash

# it's just 1 observation here
clean_edges_hacienda %>% 
  filter(Individual1 %in% ids_with_dash | Individual2 %in% ids_with_dash)

# It's 18 observations here
clean_edges_corales %>% 
  filter(Individual1 %in% ids_with_dash | Individual2 %in% ids_with_dash)

# We can fix one of these:
# "Y-NM" => "YBNM"

clean_edges %>% 
  mutate(Individual1 = ifelse(Individual1 == "Y-NM", "YBNM", Individual1),
         Individual2 = ifelse(Individual1 == "Y-NM", "YBNM", Individual2)) -> clean_edges

# and also wondering if the "Y-BM" could be a misread of "YBNM"
# It's only 2 observations
clean_edges %>% 
  filter(Individual1 == "Y-BM" | Individual2 == "Y-BM")
```

For the sake of certainty, for now, let's just remove the unresolved observations. Unfortunately, for the corales data, some of the ones we are removing also show as group interactions, so I don't know if there is a way we can keep that data. 

```{r}
# We get 638 observations here
clean_edges_no_dash <- clean_edges %>% 
  filter(!(Individual1 %in% ids_with_dash | Individual2 %in% ids_with_dash))

# clean_edges %>% 
#   filter(Individual1 %in% ids_with_dash | Individual2 %in% ids_with_dash)

clean_edges_no_dash %>% 
  count(Site)
```

I also found that some of the observations have patterns with only 3 letters, which doesn't work here.
Need to check these with Rick but for now, removing. 

```{r}

band_ids_w_3 <- band_ids[str_length(band_ids) == 3]
band_ids_w_3

# Unsure if these could match anything else
# But it is only 3 observations, so I think we might need to remove them as well
clean_edges_no_dash %>% 
  filter(Individual1 %in% band_ids_w_3 | Individual2 %in% band_ids_w_3)

filtered_indices <- which(clean_edges_no_dash$Individual1 %in% band_ids_w_3 |
                            clean_edges_no_dash$Individual2 %in% band_ids_w_3)

filtered_indices

clean_edges_no_dash[filtered_indices,]

clean_edges_no_dash$Individual2[85] <- "RBWM"
clean_edges_no_dash$Individual1[90] <- "W-WM"
clean_edges_no_dash$Individual2[312] <- "YGOM"

# Check overwritten:
clean_edges_no_dash[filtered_indices,]
```

As I was working with the attributes below, I also found a couple with only 2 letters, so checking those:
```{r}

band_ids_w_2 <- band_ids[str_length(band_ids) == 2]
band_ids_w_2

# It's only one, check how many in the observations
clean_edges_no_dash %>% 
  filter(Individual1 %in% band_ids_w_2 | Individual2 %in% band_ids_w_2)

# single row, so just remove it
which(clean_edges_no_dash$Individual1 %in% band_ids_w_2 |
                            clean_edges_no_dash$Individual2 %in% band_ids_w_2)

```


## Fix edge list for consistency in the order

We want to make sure that order is consistent (eg. BSY--YGG vs. YGG--BSY, which represent the same interaction, should always be in the same order to avoid confusion. Because we have the individuals with same band pattern, we also want to do this by site, and removing any observations that have missing bands. 

```{r}

clean_edges_with_dyad_id <- clean_edges_no_dash %>% 
  # filter(!(Individual1 %in% band_ids_w_3 | Individual2 %in% band_ids_w_3)) %>% #fixed
  filter(!(Individual1 %in% band_ids_w_2 | Individual2 %in% band_ids_w_2)) %>% 
  group_by(Site) %>% 
  # get them sorted by alphabetical
  mutate(
    sorted_Individual1 = pmin(Individual1, Individual2),
    sorted_Individual2 = pmax(Individual1, Individual2), .after = Individual2
  ) %>%
  # combine for id, use underscore _ so it doesn't confuse with id missing band
  mutate(dyad_id = paste(sorted_Individual1, sorted_Individual2, sep = "_"), .after = Individual2) %>%
  select(-sorted_Individual1, -sorted_Individual2) %>% 
  ungroup()

clean_edges_with_dyad_id %>% slice_sample(n=15)
```

I want to see how many unique values we have, and how many times we saw them, and where. We have ~600 observations, and 215 distinct dyads

```{r}
weighted_edges <- clean_edges_with_dyad_id %>% 
  group_by(
    Site
    #, Group.Interaction.
    ) %>% 
  dplyr::count(dyad_id, name = "weight") %>% 
  arrange(desc(weight))

head(weighted_edges)
```

Build a dataframe that can be used by statnet:

```{r}
edges_for_network <- weighted_edges %>% 
  separate_wider_delim(., cols = dyad_id, "_", names = c("ID1", "ID2")) 
head(edges_for_network)
```

We have the data separated by site, and I am not fully sure that's they way, but I suspect it might be relevant. Specially given we had two animals banded the same but in different sites. 
Start with the site that has most obsevations, then repeat?

```{r}
# 1. Build the network object
edges_for_network %>% 
  count(Site)

hacienda_edges <- edges_for_network %>% filter(Site == "Hacienda") %>% select(-Site) %>% ungroup()

hacienda_network <- network(
  hacienda_edges[, c("ID1", "ID2")],
  directed = FALSE,
  matrix.type = "edgelist"
)

# Add edge weights
# The edge.attribute function adds an attribute to the edges in the network object
set.edge.attribute(hacienda_network, "weight", hacienda_edges$weight)

# View a summary of the network to confirm it looks right
hacienda_network
summary(hacienda_network)

# Plot the network
plot(hacienda_network, edge.col = "gray", edge.lwd = "weight")

```

Great, this works. Lets get some very basic metrics:

```{r}
# Basic network statistics
# These account for edge weights if needed

# higher values here means more connections
degree <- degree(hacienda_network, cmode = "freeman")
print(degree)

# Unsure about this one, but its higher values are more 'connected' bridge like individuals. 
betweenness <- betweenness(hacienda_network)
print(betweenness)

# measure of reach - ?
closeness <- closeness(hacienda_network)
print(closeness)
```

# Adding attributes

Let's take a look at the attributes associated with each bird, in the raw banding data: Clean out the recaptures first

```{r}
# There is an error in the banding process here
# These are new captures but accidentally got the same color combination as a previous new bird

rawdata %>% 
  filter(Status == "N") %>% 
  anti_join(
    rawdata %>% distinct(Colors, .keep_all = TRUE) 
  )

```

These are the banding errors. Which we can probably keep since they are in different sites. So, recommendation, keep in mind when doing the network analysis, to do it by site.


```{r}
rawdata %>% 
  filter(Colors %in% c("GBBM", "RBBM"), Status == "N") %>% 
  select(Location, Colors)
```

Based on this, we create the attribute table to keep the repeat birds since they are from different locations.

```{r}
attributes <- rawdata %>% 
  filter(Status == "N")
```

```{r}

# let's get rid of the columns we're not interested in, just to make things tidier:

attributes_clean <- attributes %>% 
  select(
    Year, Month, Day, Colors, Location, Molecular_Sex, Body_Mass, UNFLT_Wing, 
    Age, Entrance_affiliation_based_on_videos_2024, Nest_affiliation..2024.
    ) %>% 
  janitor::clean_names()

head(attributes_clean)

```

Filter to hacienda to join with the network above:

```{r}
# hacienda_edges
hacienda_ids <- unique(c(hacienda_edges$ID1, hacienda_edges$ID2))

attributes_clean %>% 
  filter(location == "Hacienda") # 129 banded/captured

hacienda_attributes <- attributes_clean %>% 
  filter(colors %in% hacienda_ids)

length(hacienda_ids)
nrow(hacienda_attributes)
```

```{r}
# Want to check the nest data

hacienda_attributes %>% head()

hacienda_attributes %>% 
  count(nest_affiliation_2024)

# need to join the 'unknowns'
# figure out how to identify the one with two nests
# Q: how do the models handle missing data? thinking of the nests.

# substructure of the nest:
hacienda_attributes %>% 
  count(entrance_affiliation_based_on_videos_2024)
```

```{r}
hacienda_attributes %>% 
  count(molecular_sex)
```


```{r}

# create a network object in statnet

network <- network(edges,matrix.type="edgelist", directed=FALSE)

list.edge.attributes(network)
as.edgelist(network)
get.edge.attribute(network, "weight")
list.vertex.attributes(network)

# 

### Now we need to add some other node attribute data to the network: eg. the Nest
# affiliation of each bird in the network, body mass, etc. However, the order
# of the data in the attributes data set differs from the order in the network.
# Let's work on this issue so we have a properly labeled network:

# line up vertex attributes in the same order as the network vertex data in statnet:

# let's double check what the order is in the network:
get.vertex.attribute(network,"vertex.names")

# first, create a column with the same names in each dataset so you can perform a join:


df <- mutate(attributes, col1 = Colors)
df2 <- data.frame(col1 = network.vertex.names(network))


# now, perform a join to get them in the right order.
# As a result of this, the attributes will now be in the same
# order as the nodes in the network:

dfjoined <- left_join(df2, df, by ="col1")

str(dfjoined$Nest_affiliation..2024.)
length(dfjoined$Nest_affiliation..2024.)

# now, add these node attributes to the statnet network.

# First, add the attribute "NestID"

set.vertex.attribute(network, "NestID", dfjoined$Nest_affiliation..2024.)

get.vertex.attribute(network,"NestID")

# assess the length and number of NAs in the new network attribute, NestID

sum(is.na(dfjoined$Nest_affiliation..2024.))
length(dfjoined$Nest_affiliation..2024.)
network.size(network)

# add the attribute "EntranceID"

set.vertex.attribute(network,"EntranceID", dfjoined$Entrance_affiliation_based_on_videos_2024)

get.vertex.attribute(network,"EntranceID")

list.vertex.attributes(network)
list.edge.attributes(network)

vertexnames <- get.vertex.attribute(network,"vertex.names")
vertexnames


# add the attribute "Sex"

set.vertex.attribute(network,"Sex", dfjoined$Molecular_Sex)

get.vertex.attribute(network,"Sex")



```



```{r}
# let's also load the data in group format, as a list (since this is the input
# preferred by the "asnipe" package, and it preserves information about group interactions)


groupdata <- read.csv("../rawdata/PalmchatGroups.csv")

# let's filter out sightings with ID uncertainty:

groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual1, "\\?"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual2, "\\?"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual3, "\\?"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual4, "\\?"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual5, "\\?"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual6, "\\?"))

# and sightings with unbanded birds

groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual1, "U"))
groupdata <-  groupdata %>% filter(!str_detect(groupdata$Individual2, "U"))


# now let's put this data into a list format for the asnipe package:


groups <- groupdata %>% select(Individual1, Individual2, Individual3, Individual4,
                               Individual5, Individual6, Individual7, Individual8)

groups <- apply(groups, 1, as.list)

print(groups)

# and let's use this function from the asnipe package to create a matrix:

GBI <- get_group_by_individual(groups,
                               data_format="groups")

GBI
```
